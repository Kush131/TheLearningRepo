* Finished verifying that my genetic algorithm was working. Commit can be seen here: https://github.com/Chrispresso/PyGenoCar/commit/774ae973266b8eae30044737450b1732d4615ce9


Because of how I abstracted away some of the GA, I'm able to create different types of GAs based on the problem. For example:

~~~~
import numpy as np
from typing import Optional
from genetic_algorithm.individual import Individual
from genetic_algorithm.population import Population
from genetic_algorithm.selection import *
from genetic_algorithm.crossover import simulated_binary_crossover as SBX
from genetic_algorithm.mutation import gaussian_mutation
from matplotlib import pyplot as plt


### Different functions to test based off 
### https://en.wikipedia.org/w/index.php?title=Test_functions_for_optimization&oldid=787014841

# func_to_maximize = lambda v,w,x,y,z: -abs(abs(v**3) + (w)**2 + (x-5)**2 + (y-7)**2 + (z + 9)**2)
# func_to_maximize = lambda x,y: -abs(2*x**2 - 1.05*x**4 + ((x**6)/6) + x*y + y**2)  # 3 hump camel func
# func_to_maximize = lambda x,y: -abs( .26*(x**2 + y**2) - .48*x*y )
# func_to_maximize = lambda x,y: -abs( -20*np.exp(-.2 * np.sqrt(.5*(x**2 + y**2))) -np.exp(.5 * (np.cos(2*np.pi*x) + np.cos(2*np.pi*y))) + np.exp(1) + 20 )  # Ackley func - doesnt find (0,0)
# func_to_maximize = lambda x,y: -abs( -np.cos(x)*np.cos(y)*np.exp( -((x-np.pi)**2 + (y-np.pi)**2) ) )  # Easom func
func_to_maximize = lambda x,y: -abs( -(y + 47)*np.sin( np.sqrt( abs( (x/2) + (y+47) ) ) ) - x*np.sin( abs(x - (y+47)) ) )


class ValIndividual(Individual):
    def __init__(self, chromosome: Optional[np.ndarray] = None):
        super().__init__()
        if not chromosome is None:
            self._chromosome = chromosome
            self.decode_chromosome()
        else:
            # self.v=  np.random.uniform(50, 100)
            # self.w = np.random.uniform(50, 100)
            self.x = np.random.uniform(50, 100)
            self.y = np.random.uniform(50, 100)
            # self.z = np.random.uniform(50, 100)
            self.encode_chromosome()
            self._chromosome: np.ndarray = None

        self._fitness = -1e6

    def calculate_fitness(self):
        # self._fitness = func_to_maximize(self.v, self.w, self.x, self.y, self.z)
        self._fitness = func_to_maximize(self.x, self.y)

    @property
    def fitness(self):
        return self._fitness

    def encode_chromosome(self):
        # self._chromosome = np.array([self.v, self.w, self.x, self.y, self.z], dtype='float')
        self._chromosome = np.array([self.x, self.y], dtype='float')

    def decode_chromosome(self):
        # self.v = self._chromosome[0]
        # self.w = self._chromosome[1]
        # self.x = self._chromosome[2]
        # self.y = self._chromosome[3]
        # self.z = self._chromosome[4]
        self.x = self._chromosome[0]
        self.y = self._chromosome[1]

    @property
    def chromosome(self):
        return self._chromosome

if __name__ == "__main__":
    individuals = [ValIndividual() for _ in range(60)]
    pop = Population(individuals)
    fitness = []
    for individual in pop.individuals:
        individual.encode_chromosome()

    for generation in range(1000):
        next_pop = []
        # Decode the chromosome and calc fitness
        for individual in pop.individuals:
            individual.decode_chromosome()
            individual.calculate_fitness()

        # Get best individuals from current pop
        best_individuals = ellitism_selection(pop, 2)
        next_pop.extend(best_individuals)

        while len(next_pop) < 60:
            p1, p2 = tournament_selection(pop, 2, 4)
            c1_chromosome, c2_chromosome = SBX(p1, p2, 1)
            c1 = ValIndividual(c1_chromosome)
            c2 = ValIndividual(c2_chromosome)
            gaussian_mutation(c1, .05)
            gaussian_mutation(c2, .05)

            next_pop.extend([c1, c2])
                
        avg_fitness = sum([individual.fitness for individual in pop.individuals]) / len(pop.individuals)
        fitness.append(avg_fitness)
        pop.individuals = next_pop

    ind = max(pop.individuals, key=lambda individual: individual.fitness)
    # print('v, w, x, y, z = ',end='')
    # print(ind.v, ind.w, ind.x, ind.y, ind.z)
    print('x, y = ', end='')
    print(ind.x, ind.y)
    print(ind.fitness)

    plt.plot(fitness)
    plt.show()
~~~~

* Even just the above code allows for quick prototyping of a GA. By creating a class that inherits from `Individual`, I'm able to decide how the chromosome is formatted and how the fitness function is calculated. From there the basic structure of the GA is the same in the `__main__`. Not sure if I'm going to create a function in `population.py` to model the basic behavior, mainly from the fact that each creation of a GA may require slightly different tweaking to how the code flow goes.


## Specifics of What I Learned Today ##
* It does not seem to matter if the fitness is calculated within the while loop, which was my main concern. Because of the selection operator that papers talk about, it seems that more children are sometimes created and can compete against each other. After the children compete, only the top N are selected. In my case I want N to always be the same, which is why I can't have more children created, since I don't know the fitness until the end. Testing the above strategy on different `func_to_maximize` was able to find global maxima for most and local maxima for all. Local maxima is still going to be a problem.
* I now understand why algorithms like NEAT exist. I think one reason the local maxima problem occurs is because these individuals are competing against the entire population, which doesn't give them time to mature. In algorithms like NEAT, they are given their own niches to perform in and compete in. At the end they can be compared against the overall population, but the niches themselves all have a fitness sharing attribute.

## Stuff to test ##
* Is there a certain number of ellite individuals I should take from each generation?
* Should my mutation rate be based off the fitness of an individual, i.e. worse performers have a higher chance of mutation? This could allow for exploration early on.
* How many individuals should there be in my population?
* If I do something like this with Snake, is there a way to multi-thread this? It wouldn't make sense for each member in the population to need to compete on a screen. Can I chuck this stuff into multiple cores, etc.?
* How would this compare to PSO?